{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shyam/anaconda3/envs/py36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import *\n",
    "from keras.layers import *\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils \n",
    "from keras.utils import plot_model\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import *\n",
    "from keras.optimizers import SGD\n",
    "import cv2\n",
    "import glob\n",
    "import pydot\n",
    "import graphviz\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ZFNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZFNet implemented from scratch with Keras\n",
    "## based on the paper: Visualizing and Understanding Convolutional Networks\n",
    "\n",
    "## https://arxiv.org/pdf/1311.2901.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The data is from a dataset of flower images, with 10 different classes or types of flowers. We will resize the images to be 224x224x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/flower_images/flower_labels.csv\")\n",
    "data[\"file\"] = \"data/flower_images/\" + data[\"file\"]\n",
    "X = np.array(data.iloc(1)[0])\n",
    "y = np.array(data.iloc(1)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_split_set(X,portion,y=None):\n",
    "    '''\n",
    "    use:\n",
    "        X = iris.data\n",
    "        y = iris.target\n",
    "        X_train, X_test, y_train, y_test = split_set(X,0.1,y) for 10% used as test set\n",
    "    '''\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    size = int(X.shape[0]*portion)\n",
    "    indexlist = np.arange(X.shape[0])\n",
    "    testinds = np.random.choice(indexlist, size, replace=False)\n",
    "    traininds = np.array([x for x in range(X.shape[0]) if x not in testinds])  \n",
    "    if np.all(y == None):\n",
    "        return X[traininds],X[testinds]\n",
    "    else:\n",
    "        return X[traininds],X[testinds],y[traininds],y[testinds]\n",
    "\n",
    "X_train, X_test, y_train, y_test = cross_val_split_set(X,0.1,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reshape(y_train.shape[0],1)\n",
    "y_test = y_test.reshape(y_test.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(path,length,width):\n",
    "    img = cv2.imread(path)\n",
    "    img = np.asfarray(cv2.resize(img,(length, width)))\n",
    "    return img/255.0\n",
    "\n",
    "def read_bulk(paths):\n",
    "    result = []\n",
    "    for i in paths:\n",
    "        result.append(preprocess(i,227,227))\n",
    "    return np.array(result)\n",
    "\n",
    "result = read_bulk(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZFNet():\n",
    "    \"\"\"\n",
    "    ZFNet implemented with Keras\n",
    "    introduced in the paper \"Visualizing and Understanding Convolutional Networks\"\n",
    "    https://arxiv.org/pdf/1311.2901.pdf   \n",
    "    Parameters:\n",
    "        X: numpy array data matrix \n",
    "        y: numpy array of labels, to_categorical changes it to a sparse binary matrix\n",
    "        weights: name of file that denotes weights to load in\n",
    "    \"\"\"\n",
    "    def __init__(self,X,y,weights=\"None\"):\n",
    "        \n",
    "        self.X = X\n",
    "        self.y = to_categorical(y)\n",
    "                \n",
    "        self.weights = weights\n",
    "        self.model = None\n",
    "        \n",
    "        if self.weights == \"None\":\n",
    "            self.initialize()\n",
    "        else:\n",
    "            self.model = load_model(weights)\n",
    "        \n",
    "    def initialize(self):\n",
    "        \n",
    "        K.clear_session()\n",
    "        \n",
    "        n_outputs = self.y.shape[1]\n",
    "        height = self.X.shape[1]\n",
    "        width = self.X.shape[2]\n",
    "        \n",
    "        inp = Input(shape=(height,width,3))\n",
    "        conv1 = Conv2D(96,kernel_size=7,strides=2,border_mode='valid',activation='relu')(inp)\n",
    "        max1 = MaxPool2D(3,strides=2,border_mode='same')(conv1)\n",
    "        dropout1 = Dropout(0.5)(max1)\n",
    "        normal1 = BatchNormalization()(dropout1)\n",
    "        conv2 = Conv2D(256,kernel_size=5,border_mode='same')(normal1)\n",
    "        max2 = MaxPool2D(3,strides=2,border_mode='same')(conv2)\n",
    "        dropout2 = Dropout(0.5)(max2)\n",
    "        normal2 = BatchNormalization()(dropout2)\n",
    "        conv3 = Conv2D(512,kernel_size=3,border_mode='same')(normal2)\n",
    "        conv4 = Conv2D(1024,kernel_size=3,border_mode='same')(conv3)\n",
    "        conv5 = Conv2D(512,kernel_size=5,border_mode='same')(conv4)\n",
    "        max3 = MaxPool2D(3,strides=2,border_mode='same')(conv5)\n",
    "        dropout3 = Dropout(0.5)(max3)\n",
    "        flatten = Flatten()(dropout3)\n",
    "        dense1 = Dense(4096,activation=\"relu\")(flatten)\n",
    "        dropout4 = Dropout(0.5)(dense1)\n",
    "        dense2 = Dense(4096,activation=\"relu\")(dropout4)\n",
    "        dropout5 = Dropout(0.5)(dense2)\n",
    "        dense3 = Dense(n_outputs,activation=\"softmax\")(dropout5)\n",
    "        dropout6 = Dropout(0.5)(dense3)\n",
    "        softmax = Softmax(n_outputs)(dropout6)\n",
    "        \n",
    "        model = Model(inputs=inp,outputs=softmax)\n",
    "        model.compile(loss='categorical_crossentropy',optimizer=\"adam\",metrics=['accuracy'])\n",
    "        self.model = model\n",
    "        print(self.model.summary())\n",
    "        \n",
    "    def save_picture(self,filename):\n",
    "        plot_model(self.model, to_file=filename)\n",
    "        \n",
    "    def train(self,epochs,save=True):\n",
    "\n",
    "        self.model.fit(self.X, self.y ,validation_split=0.1, epochs=epochs,verbose=1)\n",
    "        if save == True:\n",
    "            self.model.save('saved_models/ZFNet.h5')\n",
    "        loss, acc = self.model.evaluate(self.X, self.y, verbose=0)\n",
    "        print('Train Accuracy: %f' % (acc*100))\n",
    "        \n",
    "    def predict(self,X):\n",
    "        \n",
    "        if len(X.shape) == 3:\n",
    "            X = X.reshape(1,X.shape[0],X.shape[1],X.shape[2])\n",
    "        predictions = self.model.predict(X)\n",
    "        return np.argmax(predictions)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(227, 227, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 227, 227, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 111, 111, 96)      14208     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 56, 56, 96)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 56, 56, 96)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 56, 56, 96)        384       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 56, 56, 256)       614656    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 28, 28, 1024)      4719616   \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 28, 28, 512)       13107712  \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              411045888 \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                40970     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "softmax_1 (Softmax)          (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 447,505,930\n",
      "Trainable params: 447,505,226\n",
      "Non-trainable params: 704\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "zf = ZFNet(result,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "zf.save_picture(\"../model_images/ZFNet.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 170 samples, validate on 19 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/shyam/anaconda3/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-10-2a2f9995ccd4>\", line 1, in <module>\n",
      "    zf.train(5)\n",
      "  File \"<ipython-input-6-e4da1d4f63dc>\", line 65, in train\n",
      "    self.model.fit(self.X, self.y ,validation_split=0.1, epochs=epochs,verbose=1)\n",
      "  File \"/home/shyam/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/training.py\", line 1705, in fit\n",
      "    validation_steps=validation_steps)\n",
      "  File \"/home/shyam/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/training.py\", line 1235, in _fit_loop\n",
      "    outs = f(ins_batch)\n",
      "  File \"/home/shyam/anaconda3/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 2476, in __call__\n",
      "    session = get_session()\n",
      "  File \"/home/shyam/anaconda3/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 199, in get_session\n",
      "    session.run(tf.variables_initializer(uninitialized_vars))\n",
      "  File \"/home/shyam/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 905, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/home/shyam/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1140, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/home/shyam/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1321, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/home/shyam/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1327, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/home/shyam/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1312, in _run_fn\n",
      "    options, feed_dict, fetch_list, target_list, run_metadata)\n",
      "  File \"/home/shyam/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1420, in _call_tf_sessionrun\n",
      "    status, run_metadata)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shyam/anaconda3/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shyam/anaconda3/envs/py36/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/shyam/anaconda3/envs/py36/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/shyam/anaconda3/envs/py36/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/shyam/anaconda3/envs/py36/lib/python3.6/inspect.py\", line 1483, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/shyam/anaconda3/envs/py36/lib/python3.6/inspect.py\", line 1441, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/shyam/anaconda3/envs/py36/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/shyam/anaconda3/envs/py36/lib/python3.6/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/home/shyam/anaconda3/envs/py36/lib/python3.6/posixpath.py\", line 388, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/home/shyam/anaconda3/envs/py36/lib/python3.6/posixpath.py\", line 422, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "zf.train(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zf.predict(result[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
